---
layout:     post
title:      演化算法：筛选与多样性
subtitle:   Fitness, selection and population
date:       2021-11-13
author:     Welt Xing
header-img: img/hsae/hsae.png
catalog:    true
tags:
    - 演化算法
---

## <center>Parent Selection

我们前面提到过，在parent selection步骤，我们需要在种群中选择一部分个体进行变异。我们通常会根据解的fitness大小来决定是否对其进行变异。

### Fitness proportional selection

Fitness proportional selection(FPS)用fitness的相对大小来决定选择其参与变异的概率：

$$
\Pr_{FPS}(i)=\dfrac{f_i}{\sum_{j=1}^\mu f_j}
$$

其中$f_i$表示第$i$个解的fitness，$\mu$是种群的大小。但当各个解的fitness很接近时，几乎没有选择压力(selection pressure)，也就是无法体现解的优劣程度。这时，我们可以对fitness进行处理(Windowing)：

$$
f_i=f_i-\beta^t\\
\beta^t=\min_{j\in\{1,2,\cdots,\mu\}}f_j
$$

这样能够增大解之间的差异，从而更好进行筛选。

### Ranking selection

Ranking selection(RS)也是一种parent selection方法。RS的选择概率是基于相对的fitness而不是绝对的fitness。给每一个解一个选择概率，$0\leq rank\leq\mu-1$。Linear ranking selection(LRS)用一种线性的rank来衡量fitness：

$$
\Pr_{LRS}(i)=\dfrac{2-s}{\mu}+\frac{2i(s-1)}{\mu(\mu-1)}
$$

这样设计保证了概率和为1，符合概率公理：

$$
\sum_{i=0}^{\mu-1}\Pr_{LRS}(i)=\frac{2-s}{\mu}\cdot\mu+\frac{2(s-1)}{\mu(\mu-1)}\frac{\mu(\mu-1)}{2}=1
$$

从公式中可以看出，最差个体的选择概率为$\frac{2-s}{\mu}$。对于参数$s$，允许的合理范围是$s\in(1,2]$，它表示在使用LRS方法筛选个体$\mu$次之后，选择出的最优个体的期望数。当$s$增大，**更优个体的选择概率更大，更差个体的选择概率更小**。当$\mu$是奇数，那么选择fitness为中位数的个体的概率是一个**常数**：$\frac1\mu$。下面是LRS在不同$s$下，选择不同fitness个体的概率：

| 个体 | fitness | rank | $s=1.5$ | $s=2$ |
| :--: | :-----: | :--: | :-----: | :---: |
|  A   |    1    |  0   |   0.1   |   0   |
|  B   |    4    |  1   |  0.15   |  0.1  |
|  C   |    5    |  2   |   0.2   |  0.2  |
|  D   |    7    |  3   |  0.25   |  0.3  |
|  E   |    9    |  4   |   0.3   |  0.4  |

除了线性的ranking selection，我们还可以引入指数的ranking selection(Exponential ranking selection, ERS)：

$$
\Pr_{ERS}(i)=\dfrac{1-e^{-i}}{c}
$$

其中$C$是归一化系数，因为概率的和必须为1：

$$
\sum_{i=0}^{\mu-1}\dfrac{1-e^{-i}}{c}=1\to c=\mu-\dfrac{1-e^{-\mu}}{1-e^{-1}}
$$

## <center>Sampling

### Roulette wheel

在设计好每个个体被选择的概率之后，我们就可以设计采样方法，一种简单的方法就是Roulette wheel方法，模拟赌场里面的旋转的轮盘。假设种群有6个个体，对应的轮盘就是

<img src="/img/hsae/image-20211113154338036.png" alt="image-20211113154338036" style="zoom:67%;" />

每一个扇形的弧度对应着选取某个体的概率。$a_i=\sum_{j=1}^i\Pr_{sel}(j)$。然后从均匀分布$U[0,1]$中选出一个数$r$，观察$r$落在的位置，比如上图，就相当于我们抽中了第五个个体。再举个例子，假设种群有3个个体，筛选概率分别是0.1,0.2,0.3,0.4以此将$[0,1]$区间分成四段，长度比就是概率比，从0~1随机选一个数字$r$，$r$落在哪个区间，就要筛选哪个样本，比如$r=0.4$，$r$在$0.1+0.2$和$0.1+0.2+0.3$之间，因此筛选第3个个体。

假设我们要选择$\lambda$个解去变异，理论上第$j$个个体在待变异种群(也叫做mating pool)中的个数为

$$
\lambda\cdot\Pr_{sel}(j)
$$

但实际结果（采样）往往和理论值（期望）有很大不同，我们需要一种新方法来使得理论值和实际值足够接近。

### Stochastic universal sampling

由此引入随机遍历抽样(Stochastic universal sampling)：假设要选择$\lambda$个个体，先从均匀分布$U[0,\frac1\lambda]$中选出$r$，然后将$r,r+\frac1\lambda,r+\frac2\lambda,\cdots,r+\frac{\lambda-1}{\lambda}$所在的轮盘区域对应个体选出来作为mating pool.

此时，如果$\lambda\cdot\Pr_{sel}(j)$是整数，那么mating pool中必存在这么多的个体$j$；即使不是整数，那也是$\lfloor\lambda\cdot\Pr_{sel}(j)\rfloor$或$\lfloor\lambda\cdot\Pr_{sel}(j)\rfloor+1$，与期望十分接近。

竞标赛选择法(Tournament selection, TS)只使用局部fitness信息：

- 随机选择$k$个个体，可以带重复，也可以不带重复；
- 比较这$k$个个体的fitness，选择最优的个体；
- 带放回地循环上面的过程$\lambda$次.

假设我们选择的时候允许重复，然后最优解唯一，那么被选出来的$\lambda$个个体中最少有一个最优解的概率为：

$$
1-\bigg(
1-{\mu-1\choose k-1}\bigg/{\mu\choose k}
\bigg)^\lambda=1-(1-\frac{k}{\mu})^\lambda
$$

### Uniform selection

均匀选择(Uniform selection, US)从当前种群中随机选择个体：

$$
\Pr_{US}(i)=\frac1\mu
$$

也就是带放回的抽样。

## <center>Survivor Selection

在经历了parent selection和变异之后，当前种群的组成就是$\mu$个父代解和$\lambda$个子代解。我们需要通过survivor selection缩小种群，重新回到$\mu$个个体。

### Age-based replacement

我们之前也提到过，有两种基于不同指标的淘汰方式：基于age和基于fitness。先来看基于年龄的淘汰：如果$\lambda=\mu$，我们可以直接淘汰所有的父代解，保留所有的子代解；如果$\lambda<\mu$，我们会淘汰掉年龄最大的$\lambda$个父代解，保持种群大小维持在$\mu$。

### Fitness-based replacement

基于fitness的淘汰：如果$\mu>\lambda$，那么我们会淘汰父代解中fitness最小的$\lambda$个个体；如果$\mu<\lambda$，我们会在子代解中选出fitness最大的$\mu$个个体作为下一代；但我们也可以将父代和子代综合考虑，也就是$(\mu+\lambda)$选择：从$\mu+\lambda$个个体中选出fitness最大的$\mu$个个体作为下一代。

Round-robin tournament法：对$(\mu+\lambda)$中每一个个体$x$，都从种群中随机选出$q$个其他个体作为对手比较fitness，fitness大的则是赢家，记录$x$赢的次数，然后我们选出赢的次数最多的$\mu$个个体作为我们的新种群。

> 当$q=\mu+\lambda-1$时，算法退化成$(\mu+\lambda)$选择；当$q=1$时，即使最坏的解也可能被选中。

## <center>Population diversity

父代筛选(Parent selection)和幸存筛选(Survivor selection)都会让演化算法专注于一个“峰”，因此存在陷入局部最优的可能：

![image-20211113170156063](/img/hsae/image-20211113170156063.png)

### Fitness sharing

因此，我们想让种群集中在多个峰，类比到生物学概念，就是维持种群内部的多样性。其中一个方法是fitness sharing，通过共享解的fitness，从而限制一个“峰”上的个体数：

$$
f'(i)=\dfrac{f(i)}{\sum_{i}sh(d(i,j))}
$$

其中

$$
sh(d)=\begin{cases}
1-(\frac{d}{\delta_{share}})^\alpha&\text{if }d\leq\delta_{share}\\
0&\text{otherwise}
\end{cases}
$$

观察上式，如果有多个个体集中在某处，而且彼此间距离很小(d很小)，那么$sh(d)$就会很大，进而这些个体的fitness都会有一定程度的减小，如果是基于fitness的幸存筛选，这些个体被淘汰的可能性增加，从而避免了多个个体聚集在一个“峰”上。

### Crowding

Crowding的思想是：子代解只会和相似的父代解产生竞争关系并排挤它们。比如下面的父代解$p_1,p_2$各自产生了子代解$o_1,o_2$，那么就有左边的距离关系：

![image-20211113172644351](/img/hsae/image-20211113172644351.png)

类似的，如果$p_1$产生了$o_2$，$p_2$产生了$o_1$，那么就有距离关系：

![image-20211113172734600](/img/hsae/image-20211113172734600.png)

因此，新生的子代解会将其附近的父代解顶替掉，维持了一个“峰”上的种群个体数。

![image-20211113172856897](/img/hsae/image-20211113172856897.png)

上图是采用不同的维持多样性方法而产生的结果，对于fitness sharing，越高的峰会有越多的个体，从而保持了各个不同高度峰对应个体的fitness的近似；而在Crowding中，只有子代替代父代的过程，没有fitness的参与，因此每个峰上个体数差不多。

## <center>总结

我们在这里对fitness、selection和population的管理进行了一个详细的分析和方法介绍，事实上这些都是演化算法的基本步骤，我们在不断完善演化算法的知识结构。
