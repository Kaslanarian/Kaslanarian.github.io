---
layout:     post
title:      Deep Inside Convolutional Networks：Visualising Image Classifification Models and Saliency Maps
subtitle:   文献解读：卷积神经网络可视化方法
date:       2022-03-28
author:     Welt Xing
header-img: img/genshin.jpg
catalog:    true
tags:
    - 卷积神经网络
---

原文：<https://arxiv.org/abs/1312.6034>.

这篇文章研究的是图像分类模型的可视化 （Visualization of image classification models），使用深度卷积网络(ConvNets)进行学习。作者考虑了基于计算类别分数对图像梯度的两种可视化方法：

1. 生成最大化类别得分的输入图像；
2. 计算类别的显著图（Saliency Map），针对特定的图像和类别。

文章在最后会建立基于梯度的可视化方法与反卷积网络的联系。

## Introduction

深度卷积网络现在成为大规模图像识别的网络结构选择，随之而来的就是CNN的可理解性问题。在之前的工作中，Erhan等人通过在图像空间中使用梯度上升进行优化，通过最大限度地最大化神经元活动的输入图像来可视化深度模型。该方法被用于可视化无监督深度体系结构的隐藏特征层，如深度信念网络(DBN)，后来被Le等人用来可视化类模型，由一个深度无监督自动编码器捕获。最近，Zeiler等人解决了CNN可视化的问题。对于卷积层可视化，他们提出了解卷积网络(DeconvNet)架构，其目的是从其输出近似地重构每一层的输入。

在这篇文章中，作者声称解决了深度图像分类卷积集的可视化，在大规模的ImageNet训练数据集。为此，他们做出了三项贡献：

1. 证明了CNN分类模型可以通过输入图像的数值优化得到可理解的可视化；
2. 提出了一种方法，使用一个反向传播来计算给定类在给定图像（特定图像的类显著图）；
3. 展示了基于梯度的可视化方法与反卷积之间的联系。

## 类模型的可视化

令$S_c(I)$是将图片$I$输入CNN之后，网络的第$c$类对应的输出。我们希望找到一个L2正则化的图像，使得$S_c$尽量高：

$$
\arg\max_IS_c(I)-\lambda\Vert I\Vert_2^2,
$$

$\lambda$是正则化参数。一般CNN的训练，是利用反向传播修改网络权重参数，而这里却是固定权重参数不变，更新图像。利用反向传播可以找到局部最优的图像$I$。下图就是通过上述方法计算计算出的图像（原图是杯子）：

![image-20220327130256292](/img/image-20220327130256292.png)

注意这里的$S_c$是未经softmax归一化的类得分，而不是经过softmax处理过的后验概率$P_c=\frac{\exp S_c}{\sum_c\exp S_c}$。这是因为如果这样处理后，最大化本类的$S_c$，相当于同时在最小化其他类别的得分，但我们只想考虑类别$c$。作者也通过实验证实了优化归一化后的得分的效果不好。

## 特定图像的类别显著可视化

这一节作者描述了如何查询给定图像中特定类的空间支持度（Spatial support）。给定图像$I_0$和类别$c$，和一个CNN的打分函数$S_c(I)$，我们想基于对$S_c(I_0)$的影响，对$I_0$的像素进行排序。

考虑类别$c$的线性打分模型

$$
S_c(I)=w_c^TI+b_c
$$

上式的$I$已经被展开，也就是向量化了。$w_c$和$b_c$是模型的权重与偏置。$w_c$对应图像像素对$S_c$的影响。

而在CNN中，$S_c$显然不是线性的，因此我们试图计算其一阶近似：

$$
S_c(I)\approx w^T I+b,w=\dfrac{\partial S_c}{\partial I}\bigg\vert_{I_0}
$$

另一种解释是梯度的大小表明该位置的像素影响类别得分的能力。因此影响大的像就有可能对应图像中的物体位置。下图就是通过上述方法计算出的显著图：

![image-20220327130412107](/img/image-20220327130412107.png)

### 类别显著性提取

给定$m$行$n$列的图像$I_0$和类别$c$，类别显著图$M\in\mathbb{R}^{m\times n}$可以按照下面这样计算：

1. 通过反向传播计算梯度$w$；
2. 对于灰度图像，显著图就是对应位置梯度的绝对值，而对于多通道图像，比如彩图，显著图对应的是该像素点通道梯度的最大值。

需要注意的是，显著图是使用在图像标签上训练的CNN来提取的，因此不需要额外的注释（如对象边界框或分割掩码）。针对单个类的特定于图像的显著性映射的计算是非常快的，因为它只需要一个反向传播。

### 弱监督目标定位

弱监督的类显著图。在给定图像中编码对象的给定类的位置，因此可以用于目标定位（尽管只在图像标签上进行训练）。在这里，文中简要描述了一个简单的目标定位过程，文章将其用于ILSVRC-2013挑战的定位任务。由于这部分内容需要额外的CV知识，同时和本文核心内容关系不大，故略去不提。读者若有兴趣可阅读原文。

## 和反卷积网络的联系

作者在这一部分揭示了反卷积网络重构下的第$n$层输入$X_n$等价或类似于计算神经元激活$f$对$X_n$的梯度，因此反卷积网络有效对应卷积神经网络的梯度反向传播。

对于卷积层$X_{n+1}=X_n\star K_n$，梯度计算方法为

$$
\dfrac{\partial f}{\partial X_n}=\dfrac{\partial f}{\partial X_{n+1}}\star\widehat{K_n}
$$

其中$K_n$和$\widehat{K}_n$是卷积核和它的翻转。翻转卷积核的卷积对应反卷积网络的第$n$层重构：

$$
R_n=R_{n+1}\star\widehat{K}_n
$$

对于ReLU激活层，$X_{n+1}=\max(X_n,0)$，由于激活函数导数不连续，因此基于次梯度（<https://welts.xyz/2021/09/30/lasso/>）求导得到

$$
\dfrac{\partial f}{\partial X_n}=\dfrac{\partial f}{\partial X_{n+1}}\mathbb{I}(X_n>0)
$$

这里$\mathbb{I}$是对元素的示性函数，满足命题返回1，否则返回0。这与反卷积的ReLU有些许差别，反卷积网络中对激活层的重构为

$$
R_n=R_{n+1}\mathbb{I}(R_{n+1}>0)
$$

示性函数是对输出进行计算，而不是输入。

最后是最大池化层

$$
X_{n+1}(p)=\max_{q\in\Omega(p)}X_n(q)
$$

其中对于位置$p$，$q$应当是输入中对应的那片区域。其基于次梯度的求导：

$$
\dfrac{\partial f}{\partial X_n(s)}=\dfrac{\partial f}{\partial X_{n+1}(p)}\mathbb{I}(s=\arg\max_{q\in\Omega(p)}X_n(q)).
$$

这里的最大池化对应反卷积架构中的最大池化的"switch"。

我们可以总结，除了ReLU层，使用反卷积网络计算近似特征图重构$R_n$和使用反向传播计算$\partial f/\partial X_n$（也就是文中提出的算法）等价。因此，基于梯度的可视化可以视作之前CNN可视化工作的推广，因为这里的方法也适用于全连接层，而不仅限于卷积层。

应该注意的是，文中的类模型可视化描述了一个类的概念，由CNN记忆，并不是特定于任何图像给定。同时，类别显著性可视化是特定于图像的，在这个意义上与特定于图像的卷积层可视化有关（主要区别在于我们将神经元可视化在一个全连接的层，而不是卷积层）。

## 总结

本文提出了两种用于深度分类的可视化技术。第一种方法是生成一个人工图像，它代表了某个类别感兴趣的图像。第二个是计算一个特定于图像的类显著图，突出显示给定图像的区域，不同的类别会生成不同的图。我们证明，这种显著图可以用于初始化基于图形切割的对象分割，而不需要训练专门的分割或检测模型。最后证明了基于梯度的可视化技术是反卷积网络重建过程的推广。
