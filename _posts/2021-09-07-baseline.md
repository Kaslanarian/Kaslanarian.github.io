---
layout:     post
title:      sklearn数据集的baseline
subtitle:   获取与总结
date:       2021-09-07
author:     Welt Xing
header-img: img/background.jpg
catalog:    true
tags:
    - 机器学习
---

## <center>前言

笔者在编写模型时，常常用`sklearn`中较小的数据集验证自实现模型的能力。相比于直观的分类准确率，在回归问题中，我们无法通过均方误差直接判断模型效果，比如说：均方误差为10，这个模型是好是坏？因此我们只能进行模型间比较，比如：模型A的性能在模型B和模型C之间。我们这里主要是探究一些经典模型在`sklearn`中各个数据集上的表现，也就是baseline，为后面自实现模型的性能测试提供参考。

## <center>数据集介绍

`sklearn`中的小数据集也被称作"toy datasets"，每个数据集都对应不同的机器学习任务，我们逐一介绍。

- `load_boston`：波士顿房价数据集，是13个特征和1个输出的回归任务，共506个样本；
- `load_iris`：鸢尾花数据集，4个特征的三分类任务，共150个样本；
- `load_diabetes`：糖尿病数据集，10输入1输出的回归任务，共442个样本；
- `load_digits`：手写数字数据集，64输入（8\*8的图片），10个类别的分类任务，共1797个样本；
- `load_linnerud`：体能锻炼数据集，3输入3输出的回归任务，只有20个样本；
- `load_wine`：酒类数据集，13特征的三分类问题，共178个样本；
- `load_breast_cancer`：乳腺癌数据集，30特征的二分类问题，共569个样本。

## <center>实现方法

利用`sklearn`中提供的模型，一般使用默认参数的模型进行学习并测试，重复多次，然后对效果取均值，最大最小值：

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

train_ratio = 0.7
EPOCHES = 1000
X, y = load_iris(return_X_y=True)
model = LogisiticRegresson(max_iter=500) # 默认参数不收敛
acc_list = []

for epoch in range(EPOCHES):
    X_train, X_test, y_train, y_test =train_test_split(X, y, train_size=train_ratio)
    model.fit(X_train, y_train)
    pred = model.predict(X_test)
    acc_list.append(accuracy_score(y_test, pred))
    
acc = sum(acc_list) / EPOCHES # 准确率均值
min_acc, max_acc = min(acc_list), max(acc_list)
```

## <center>分类模型的性能基线

常用的分类模型：对率回归、K近邻、支持向量机、朴素贝叶斯、决策树，这里不考虑集成学习算法。

表格中的数据表示准确率的最小值，均值和最大值：

|                            |      iris$^*$      |        wine        |    breast_cancer    |
| :------------------------: | :----------------: | :----------------: | :-----------------: |
| Logistic Regression$^{**}$ | 86.7%,96.2%,100% |  88.9%,98%,100%  | 93.6%,97.6%,100%  |
|            kNN             | 84.4%,96.2%,100% |  87%,95.9%,100%  | 91.8%,96.4%,100%  |
|           NuSVC            |  80%,95.6%,100%  | 88.9%,97.9%,100% |  88.3%,94%,98.8%  |
|         GaussianNB         |  86%,95.2%,100%  |  87%,97.3%,100%  | 86.5%,93.2%,98.2% |
|       Decision Tree        |  80%,94.5%,100%  | 75.9%,90.5%,100% | 85.4%,92.5%,97.7% |

\*：所有的输入都进行了标准化处理，对于SVM和kNN模型来说很重要；
\*\*：这里逻辑回归需要修改参数，否则无法收敛.

举例来说，我们自实现了一个决策树模型：[Kaslanarian/EnsembleCode: 自实现集成学习算法 (github.com)](https://github.com/Kaslanarian/EnsembleCode/blob/main/tree.py)，然后进行上面的测试，测试结果：

|      | iris  | wine  | breast_cancer |
| :--: | :---: | :---: | :-----------: |
| min  | 82.2% | 66.6% |     87.1%     |
| avg  | 94.8% | 90.3% |     92.3%     |
| max  | 100%  | 100%  |     97.1%     |

再和上面的Decision Tree进行比较，发现自实现的决策树性能和`sklearn`的实现差不多，唯一需要改善的就是时间问题。

## <center>回归模型的性能基线

常用的回归模型：线性回归，k近邻回归，支持向量回归，决策树回归。我们用均方误差来度量模型性能。

表格中的数据表示均方误差的最小值，均值和最大值：

|                   |     Boston$^*$      |         diabetes          |        linnerud         |
| :---------------: | :-----------------: | :-----------------------: | :---------------------: |
| Linear Regression | 13.67, 24.07, 43.57 | 2220.33, 3046.38, 4278.80 | 28.65, 320.40, 1822.79  |
|        kNN        | 8.61, 22.46, 42.98  | 2336.18, 3674.59, 5067.32 |  38.42, 271.84, 599.53  |
|       NuSVR       | 12.54, 33.20, 58.11 | 3934.73, 5104.14, 7016.68 | 44.80, 229..69, 570.98  |
|   Decision Tree   | 9.40, 22.46, 55.47  | 4421.03, 6512.10, 9724.13 | 54.67, 409.234, 1185.67 |

\*: 我们对所有的输入进行了标准化处理

比如我们用自实现的决策树：[Kaslanarian/EnsembleCode: 自实现集成学习算法 (github.com)](https://github.com/Kaslanarian/EnsembleCode/blob/main/tree.py)对数据进行回归：

|      | Boston | diabetes | linnerud |
| :--: | :----: | :------: | :------: |
| min  | 17.08  | 3263.32  | 暂未实现 |
| avg  | 33.45  | 4320.77  | 暂未实现 |
| max  | 60.09  | 5835.06  | 暂未实现 |

将这里的结果与上面的决策树回归结果进行比较，发现我们自设计的决策树回归在波士顿房价数据集表现不如`sklearn`模块，但在糖尿病数据集表现更好。我们目前还没有设计多元回归。
