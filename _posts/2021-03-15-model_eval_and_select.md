---
layout:     post
title:      机器学习导论
subtitle:   模型评估和选择
date:       2021-03-15
author:     Welt Xing
header-img: img/post-bg-desk.jpg
catalog:    true
tags:
    - 课程
    - 机器学习
---

弄清目的，想要什么，这影响评价结果（和算法）.

- 泛化误差&经验误差

- 过拟合（过配）——经验误差不应越小越好

- 没有最好的解决方案，去解决找到过拟合和欠拟合间的平衡点

## 评估方法

- 留出法，交叉验证法和自助法

- hold-out法的缺陷1：80个样本训练出的模型并不是100个样本训练出的模型，但我们要把前面模型的误差去估计后一个模型的误差

- hold-out返回的模型是用所有样本训练出的模型

- hold-out法的缺陷2：样本使用率不高，存在总没被训练或总没被用来测试的样本

- k-fold交叉验证法，极端情况是留一法，用$err_{99}$去逼近$err_{100}$.

- k-fold缺陷：50个男生50个女生随机猜测，留一出一个男生，但$M_{99}$会根据概率猜是女生.

- 自助法缺陷：改变了数据分布

- 算法参数（超参数）和模型参数，比如：多项式拟合的$degree$是算法参数，而多项式系数是模型参数.

- 验证集是专门用来调参数的，不同于训练集.

- 不能用测试集来调参，调参的数据来源于训练集.

## 性能度量

- 回归任务常用均方误差（MES）：

    $$
    E(f;D)=\dfrac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2
    $$

    这里的$\frac{1}{m}$是为了求导数时便于计算.

- 查准（Precision）和查全（Recall），以及$F_1$度量.

## 比较检验