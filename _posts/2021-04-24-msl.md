---
layout:     post
title:      统计学习方法(一)
subtitle:   方法概论
date:       2021-04-24
author:     Welt Xing
header-img: img/static_learning_header.jpg
catalog:    true
tags:
    - 机器学习
---

## 引言

闲暇之余，拜读李航老师的《统计学习方法》，并与《机器学习导论》中的内容进行呼应和补充，从而加深对机器学习的理解.

## 统计学习方法概论

> 如果一个系统能够通过执行某个过程改善它的性能，这就是学习。 ——$\text{Herbert A. Simon}$

机器学习往往指的就是“统计机器学习”. 数据的基本假设是**具有一定的统计规律性**.

$$
\text{Statistic learning}\begin{cases}
\text{supervised learning}\\
\text{unsupervised learning}\\
\text{semi-supervised learning}\\
\text{reinforcement learning}\\
\end{cases}\\
\text{Statistic learning method}\begin{cases}
\text{model}\\
\text{strategy}\\
\text{algorithm}
\end{cases}
$$

### 监督学习

预测任务根据输入X和输出Y进行分类：

1. 输入输出均连续$\to\text{regression}$
2. 输出为有限离散$\to\text{classification}$
3. 输入输出都是变量序列$\to\text{tagging}$

监督学习的基本假设就是输入和输出具有联合概率分布$P(X,Y)$.

监督学习的模型可以是概率模型$(P=(Y\vert X))$或非概率模型$(Y=f(X))$.

形式化监督学习问题：

![supervised](https://2020.iosdevlog.com/2020/03/19/slm/Model.png)

预测方法：

$$
\arg\max_{y_{N+1}}\hat{P}(y_{N+1}\vert x_{N+1})
$$

或

$$
{y}_{N+1}=\hat{f}(x_{N+1})
$$

分别代表分类和回归.

### 统计学习三要素

#### 模型

假设空间中的模型一般有无数个:

$$
\mathcal{F}=\{f|Y=f(X)\}\text{ or }\mathcal{F}=\{P\vert P(Y\vert X)\}
$$

这样的函数/条件概率是由参数决定的函数族/条件概率分布族：

$$
\mathcal{F}=\{f|Y=f_\theta(X),\theta\in\mathbb{R}^n\}\text{ or }\mathcal{F}=\{P\vert P_\theta(Y\vert X),\theta\in\mathbb{R}^n\}
$$

分别称之为非概率模型和概率模型.

#### 策略

也就是选择模型的依据.

损失函数/代价函数：

$$
\text{loss function}
\begin{cases}
\text{0-1 loss function:}L(Y,f(X))\begin{cases}
1,Y\neq f(X)\\
0,Y= f(X)\\
\end{cases}\\
\text{quadratic loss function:}L(Y,f(X))=(Y-f(X))^2\\
\text{absolute loss function:}L(Y,f(X))=\vert Y-f(X)\vert\\
\text{logarithmic loss function:}L(Y,P(Y|X))=-\log P(Y\vert X)\\
\end{cases}
$$

> 最后一个就是对数似然损失函数.

损失函数的期望被称为风险函数/期望损失：

$$
R_{\text{exp}}(f)=E_P[L(Y,f(X))]=\int_{\mathcal{X}\times\mathcal{Y}}L(y,f(x))P(x,y)\mathrm{d}x\mathrm{d}y
$$

> $P(X,Y)$就是输入输出的联合概率分布.

学习的目标就是选择期望风险最小的模型. 必须要知道联合概率分布，但如果知道了也就没有学习必要了. 所以监督学习是一个**病态问题**.

模型的经验风险/经验损失：

$$
R_{\text{emp}}(f)=\dfrac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$

大数定律告诉我们：

$$
\lim_{N\to\infty} R_{\text{emp}}(f)=R_{\text{exp}}(f)
$$

但现实样本很少，所以需要对经验风险进行矫正，这就关系到监督学习的两个基本策略：**经验风险最小化**和**结构风险最小化**.

经验风险最小化（ERM）认为经验风险最小的模型最优：

$$
\min_{f\in\mathcal{F}}\dfrac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$

> 概率统计中的极大似然估计就是经验风险最小化的一个例子.

但显然这种策略会导致过拟合，从而提出结构风险最小化（SRM）：

$$
R_{\text{srm}}(f)=\dfrac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$

多出来的部分叫做正则化项/罚项.$J(f)$是模型的复杂度，是定义在$\mathcal{F}$上的**泛函**，表示对复杂模型的惩罚. $\lambda\ge0$是系数，用于权衡经验风险和模型的复杂度.

SRM策略认为结构风险最小的策略最优：

$$
\min_{f\in\mathcal{F}}\dfrac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))+\lambda J(f)
$$

> 在周老师看来，后面的$\lambda J(f)$才叫做结构风险，也就是优化目标=经验风险+结构风险. 这里还是采用李航老师的定义，即经验风险$\in$结构风险.

### 模型评估和选择

#### 训练误差和测试误差

过于简单，略去.

#### 过拟合和模型选择

《机器学习》中对过拟合的解释是：模型把数据的特性当作一般属性；而在《统计学习方法》中，过拟合被归因于模型的复杂度过高. 正则化和交叉验证是常用的模型选择方法。

### 正则化和交叉验证

和前面的结构风险对应，正则化一般具有如下形式：

$$
\min_{f\in\mathcal{F}}\dfrac{1}{N}L(y_i,(x_i))+\lambda J(F)
$$

常用$L_1$范数和$L_2$范数来表示正则化项：

$$
L(w)=\dfrac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2+\dfrac{\lambda}{2}\Vert w\Vert_2^2\\
L(w)=\dfrac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2+\lambda\Vert w\Vert_1\\
$$

> 从贝叶斯估计的角度来看，正则化项对应的是模型的先验概率，可以假设复杂的模型由较大的先验概率，简单的模型有较小的先验概率.

如果数据充足，我们会将数据三分成训练集、验证集和测试集，分别用于训练出复杂度不同的多个模型、选出最优模型和评估模型. 但现实是数据不够充足，所以引入了交叉验证法，删去了验证集，以训练多次作为补偿，有简单交叉验证，S折交叉验证和留一交叉验证，在此按下不表.

### 泛化能力

首先我们从理论上分析泛化误差，假设我们学到的模型是$\hat{f}$，那么用这个模型对未知数据预测的误差就是泛化误差：

$$
R_{\text{exp}}(\hat{f})=\int_{\mathcal{X}\times\mathcal{Y}}L(y,\hat{f}(x))P(x,y)\mathrm dx\mathrm{d}y
$$

事实上，泛化误差就是所学习到的模型的经验风险.

通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣. 泛化误差上界有一些性质：

1. $\lim_{N\to\infty} f(N)=0$也就是，样本数越多，泛化上界趋于0.
2. 假设空间容量越大，模型越难学，泛化误差上界越大.

考虑$N$维空间中的二分类问题，即$X =\mathbb{R}^n,Y\in\{−1, +1\}$. 假设空间是函数的有限集合$\\{f_1,f_2,...,f_d\\}$，其中$d$是函数个数. 我们选取0-1损失作为损失函数，$f\in\mathcal{F}$，则关于$f$的期望风险和经验风险分别是

$$
R(f)=E[L(Y,f(X))]\\
\hat{R}(f)=\dfrac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))
$$

经验风险最小化函数为

$$
f_N=\arg\min_{f\in\mathcal{F}}\hat{R}(f)
$$

而我们更关心它的泛化能力：

$$
R(f_N)=E[L(Y,f_N(X))]
$$

下面讨论从有限集合$\mathcal{F}$中任意选出函数$f$的泛化误差上界.

**定理**：对于二分类问题，当假设空间是有限个函数的集合$\mathcal{F}=\\{f_1,f_2,...,f_d\\}$时，对于任意一个函数$f\in\mathcal{F}$，至少以概率$1-\delta$，以下不等式成立：

$$R(f)\lt\hat{R}(f)+\varepsilon(d,N,\delta)$$

其中，

$$\varepsilon(d,N,\delta)=\sqrt{\dfrac{1}{2N}\big(\log d+\log\dfrac{1}{\delta}\big)}$$

[定理证明](https://welts.xyz/2021/04/24/generalize_prove/)

### 生成模型和判别模型

监督学习方法分为生成方法和判别方法，所学到的模型称为生成模型和判别模型.

生成方法由数据学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y\vert X)$作为预测的模型，即生成模型：

$$P(Y\vert X)=\dfrac{P(X,Y)}{P(X)}$$

典型的生成模型：朴素贝叶斯法和隐马尔可夫模型.

判别方法则由数据直接学习决策函数$f(X)$或者条件概率分布$P(Y\vert X)$作为预测模型，即判别模型，目前学习的决策树，SVM等都是判别模型.

生成方法的特点：

1. 可以还原出联合概率分布；
2. 收敛速度更快；
3. 存在隐变量时仍可以使用生成方法.

判别方法：

1. 直接学习，往往学习准确率更高；
2. 直接学习可以对数据进行各种程度上的抽象，定义特征并使用特征，从而简化学习问题.

### $\text{Other issue}$

什么是标注问题$(\text{tagging})$？

标注问题也是监督学习问题，可以认为是分类问题的推广，分为学习和标注两个过程. 首先给定一个训练数据集：

$$T=\{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}$$

这里$x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})^\top,i=1,2,\cdots,N$，是输入观测序列，$y_i=(y_i^{(1)},y_i^{(2)},\cdots,y_i^{(n)})^\top,i=1,2,\cdots,N$是相应的输出标记序列，$n$是序列长度，对于不同样本可以有不同值，学习系统构建的模型表示为下面的条件分布：

$$P(Y^{(1)},Y^{(2)},\cdots,Y^{(n)}\vert X^{(1)},X^{(2)},\cdots,X^{(n)} )$$

标注系统的功能是对一个观测序列$x_{N+1}=(x_{N+1}^{(1)},x_{N+1}^{(2)},\cdots,x_{N+1}^{(n)})^\top$，找到使上面的条件概率最大的输出序列$y_{N+1}$.
