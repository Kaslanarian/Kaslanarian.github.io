---
layout:     post
title:      C++构建Matrix类(9)
subtitle:   求解特征向量从而实现特征分解
date:       2021-02-26
author:     Welt Xing
header-img: img/matrix_equations.png
catalog:    true
categories: matrix-c
tags:
    - matrix-c
    - 线性代数
---

# 特征值，特征向量和特征分解

## 特征向量的求解

前面的文章已经告诉我们，如果知道矩阵$A$的一个特征值$\lambda$，那么我们只需要解齐次线性方程组

$$
(A-\lambda E)x=0
$$

由于$\det(A-\lambda E)=0$，所以解必然是$n-r$个线性无关的向量：$\beta_1,\beta_2,...\beta_{n-r}$，它们的任意线性组合都是$\lambda$对应的特征向量：

$$
A\beta_1=\lambda\beta_1,A\beta_2=\lambda\beta_2\to
\begin{aligned}
A(k_1\beta_1+k_2\beta_2)
&=k_1A\beta_1+k_2A\beta_2\\
&=k_1\lambda\beta_1+k_2\lambda\beta_2\\
&=\lambda(k_1\beta_1+k_2\beta_2)\\
\end{aligned}
$$

我们可以据此用程序模拟计算出矩阵$A$的特征向量：

```cpp
matrix_pair eigen_vector(Matrix m) {
    int n = m.get_column_number();

    bool is_first = true;

    // 删去特征值vector中重复的部分，也就是集合化
    vec2double unique_eigens = to_set(eigens);

    // 特征值按绝对值大小排序，符合MATLAB的规范
    std::sort(unique_eigens.begin(), unique_eigens.end(),
              [](double a, double b) { return std::abs(a) > std::abs(b); });

    Matrix ret, solution;
    for (double eigen_value : unique_eigens) {
        // 对应解方程组 : (A-λI)x = 0
        solution = linear_solve(m - eigen_value * eye(n));
        for (int i = 0; i < solution.get_column_number(); i++) {
            double norm_col = 0;
            for (int j = 0; j < solution.get_row_number(); j++) {
                norm_col += solution[j][i] * solution[j][i];
            }
            norm_col = sqrt(norm_col);
            // 将每一列(每一个特征向量)归一化
            for (int j = 0; j < solution.get_row_number(); j++) {
                solution[j][i] /= norm_col;
            }
        }
        if (is_first) {
            ret = solution;
            is_first = false;
        } else {
            ret = *cat(&ret, &solution);
        }
    }
    // 返回一个矩阵pair：特征值构成的对角阵和对应的特征向量
    return matrix_pair(diag(eigens), ret);
}
```

我们运行下面的测试程序：

```cpp
using namespace std;
int main() {
    Matrix A = Matrix(3, 3);
    cin >> A;
    matrix_pair result = eigen_vector(A);
    cout << result.first << endl
         << result.second << endl;
    return 0;
}
```

计算结果：![结果](/img/eigen_vec_test.png)

我们用`OCATVE`去计算该矩阵的特征值和特征向量以验证结果：

```matlab
>> A = [6 2 4; 2 3 2; 4 2 6];
>> [X, Y] = eig(A)
X = 
    0.59628     0.44721     0.66667
    0.29814    -0.89443     0.33333
   -0.74536     0.00000     0.66667
Y = 
    2.0000      0           0
    0           2.00000     0
    0           0           11.0000
```

由于算法不同，导致$\lambda=2$的一个特征向量不一样：

$$
\begin{bmatrix}
-0.7071\\0.0000\\0.7071
\end{bmatrix}\to
\begin{bmatrix}
-\frac{\sqrt{2}}{2}\\0\\\frac{\sqrt{2}}{2}
\end{bmatrix}
$$

只需要验证：

$$
\begin{bmatrix}
6-2&2&4\\
2&3-2&2\\
4&2&6-2\\
\end{bmatrix}\begin{bmatrix}
-\frac{\sqrt{2}}{2}\\0\\\frac{\sqrt{2}}{2}
\end{bmatrix}=0
$$

即可，事实上也的确是0，说明`matrix-c`的计算结果是正确的

## 特征分解

