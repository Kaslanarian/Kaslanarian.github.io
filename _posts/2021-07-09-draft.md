---
layout:     post
title:      Title
subtitle:   Subtitle
date:       2021-07-09
author:     Welt Xing
header-img: img/genshin.jpg
catalog:    true
tags:
---
<subject predicate object>

resource : web browser可以找到的叫做resource，用URI（namespace）指定，

`rdf:about`后面的就是主语，主语一定是一个URI；

object : literal or URI

```pseudocode
function Banker():
	if Request[i] <= Need[i]:
		assert
	if Request[i] > Available[i]:
		assert
	/* 试分配 */
	Allocation[i] += Request[i]
	Available[i] -= Request[i]
	Need[i] -= Request[i]
	/* 安全检测 */
	Work  <- Avaliable
	possible <- true
	rest     <- all process
	found    <- false
	for process k in rest:
		if Need[k] <= Work:
			found <- true
			release resource of k
			work += Allocation[k]
			rest.remove(k)
			k += 1
	if not found:
		possible <- false
		Allocation[i] -= Request[i]
		Available[i] += Request[i]
		Need[i] += Request[i]	
	
```

```C
type RWMonitor = Monitor {
    Cond write, read;
    int read_count = wait_count = write_count = 0;
    InterfaceModule IM;
    define start_write, start_read, end_write, end_read;
    use wait, signal, enter, leave;
}
```

$$
\begin{aligned}
\dfrac{\part}{\part x_j}\dfrac{e^{x_j}}{\sum_{i=1}^l e^{x_i}}
&=\dfrac{\part}{\part x_j}\dfrac{e^{x_j}}{t+e^{x_j}}\\
&=-\dfrac{\part}{\part x_j}\dfrac{t}{t+e^{x_j}}\\
&=-t\dfrac{e^{x_j}}{(t+e^{x_j})^2}\\
&=-\dfrac{e^{x_j}(e^{x_j}-\sum_{i=1}^lx_i)}{(\sum_{i=1}^l x_i)^2}\\
&=\dfrac{e^{x_j}\sum_{i=1}^lx_i-e^{2x_i}}{(\sum_{i=1}^l x_i)^2}\\
&=\hat{y}_j(1-\hat{y}_j)
\end{aligned}
$$

$$


\begin{aligned}
\dfrac{\part E}{\part w_{hj}}
&=\dfrac{\part E}{\part\hat{y}_j}\cdot\dfrac{\part\hat{y}_j}{\part z_j}\cdot\dfrac{\part z_j}{\part\beta_j}\cdot\dfrac{\part\beta_j}{\part w_{hj}}\\
&=-\dfrac{y_j}{\hat{y}_j}\cdot\hat{y}_j(1-\hat{y_j})\cdot b_h\\
&=-y_j(1-\hat{y}_j)b_h\\

\dfrac{\part E}{\part\theta_j}&=\dfrac{\part E}{\part\hat{y}_j}\cdot\dfrac{\part\hat{y}_j}{\part z_j}\cdot\dfrac{\part z_j}{\part\theta_j}\\
&=y_j(1-\hat{y}_j)\\

\dfrac{\part E}{\part v_{ih}}
&=\dfrac{\part E}{\part\hat{y}}\cdot\dfrac{\part\hat{y}}{\part z}\cdot\dfrac{\part z}{\part\beta}\cdot\dfrac{\part\beta}{\part b_h}\cdot\dfrac{\part b_h}{\part\alpha_h}\cdot\dfrac{\part\alpha_h}{\part v_{ih}}\\
&=\sum_{i=1}^l-y_j(1-\hat{y}_j)w_{hj}\cdot f'(\alpha_h-\gamma_h)\cdot x_i\\
&=\sum_{i=1}^l-y_j(1-\hat{y}_j)w_{hj}\cdot b_h(1-b_h)\cdot x_i\\
&=b_h(1-b_h)x_i\sum_{j=1}^lw_{hj}y_j(\hat{y}_j-1)\\

\dfrac{\part E}{\part \gamma_h}
&=\dfrac{\part E}{\part\hat{y}}\cdot\dfrac{\part\hat{y}}{\part z}\cdot\dfrac{\part z}{\part\beta}\cdot\dfrac{\part\beta}{\part b_h}\cdot\dfrac{\part b_h}{\part\gamma_h}\\
&=b_h(1-b_h)\sum_{j=1}^lw_{hj}y_j(\hat{y}_j-1)\\
\end{aligned}
$$

$\textbf{function }\text{SelectAction}(s,d)$:
	$\textbf{loop}$
		$\text{Simulate}(s,d,\pi_0)$
	$\textbf{return }\arg\max_{a}Q(s,a)$
$\textbf{function }\text{Simulate}(s,d,\pi_0)$:
	$\textbf{if }d=0:$
		$\textbf{return }0$
	$\textbf{if }s\notin T$
		$\textbf{for }a\in\mathcal{A}(s)$:
			$(N(s,a),Q(s,a))\gets(N_0(s,a),Q_0(s,a))$
		$T=T\cup\{s\}$
		$\textbf{return }\text{Rollout}(s,d,\pi_0)$
	$a\gets\arg\max_{a\in\mathcal{A}(s)}Q(s,a)+c\sqrt{\dfrac{\log(N,s)}{N(s,a)}}$
	$(s',r)\sim G(s,a)$
	$q\gets r+\gamma\text{Simulate}(s',d-1,\pi_0)$
	$N(s,a)\gets N(s,a)+1$
	$Q(s,a)\gets Q(s,a)+\dfrac{q-Q(s,a)}{N(s,a)}$
	$\text{return }q$

# 接线规则

- MPU ：$\text{VCC}\to5\text{V},\text{GND}\to*,\text{SCL}\to*,\text{SDA}\to*$

- Reciever：![image-20210520235006246](/img/image-20210520235006246.png)

  数组下标法指定：

1. $R[0,2](\text{CH4})\to\text{Digital8}$
2. $R[1,2](\text{CH3})\to\text{Digital9}$
3. $R[2,2](\text{CH2})\to\text{Digital}\sim10$
4. $R[3,2](\text{CH1})\to\text{Digital}\sim 11$
5. $R[3,0](\text{CH1})\to4$号舵机$\text{esc}$的黑线
6. $R[3,1](\text{CH1})\to4$号舵机$\text{esc}$的红线

- 电调的其余线：舵机$1,2,3,4$号的信号线分别接$4,\sim5,\sim6,7$

一阶逻辑的函数和谓词：函数无法判断真假，因为表示名词的性质，但谓词表示一个陈述句，可判断真假；但两者都可以包含一个参数$f(a),P(a),P(f(a)),f(P(a))$
$$
\begin{aligned}
x+y&=5\\
\exists y(x+y&=5)\\
\exists x\exists y(x+y&=5)
\end{aligned}
$$
有free状态就无法判断



$\emptyset\models\forall r.A\sqsubseteq\exists r.A$

$\empty\models\top\sqsubseteq\neg(\forall r.A)\sqcup\exists r.A$

$\emptyset\models\top\sqsubseteq\exists r.\neg A\sqcup\exists r.A$
$$
\begin{aligned}
S_0=\{x:\forall r.A\sqcap\forall r.\neg A\}\\
\end{aligned}
$$
Sushi
	AvocadoMaki
	CucumberMaki
Ingredient
	Avocado
	Mayo
	Nori
	Cucmber
	SeasameSeedsFruit
	Avocado
Vegatable
	Aubergine
	Cucumber
	SeasameSeeds
	Nori
	Lettuce
	Onion
	Chive
	Chilli
	Shiso
	Wasabi
	Pumpkin
Meat
	Livestock
		Chicken
		Beef
		Duck
	Seafood
		Salmon
		Tuna
		Masago
		Surimi
		Prawn
Sauce
	Mayo
	TonkatsuSauce
	HoisinSauce
	SrirachaSauce
	PonzuSauce
	Caviar
	PonzeuSalsa
Powder
	ShichimiPowder
	KoreanRedPepperPowder



Assume that we have a TBox $\mathcal{T}$ with $n$ inclusions and each has at most $m$ concept names. There're at most $m-1$ times that we apply rules because each time we apply the rule (except the last one), the inclusion we operate will be split into 2 parts and one of them must be normalized. As to the other one, it's original concept names will decline by one until all of them are normalized. So after $O(n(m-1))$ times of rules application that $\mathcal{T}$ is in normal form. 

Now we discuss the situation that there're concepts equations in $\mathcal{T}$. Supposed that all of the inclusions in $\mathcal{T}$ are equations. Then we just need to use the last rule for $n$ times to split each equation into 2 parts. Then we need normalize for $O(2n(m-1))$ times to repeat the process we discuss in last paragraph. So we need $O(2n(m-1)+n)=O(n(2m-1))$, which is still linear. 



由于我们有$y_i=\boldsymbol{u}_i^\top(\boldsymbol{x}-\boldsymbol\mu_x)$，不妨设$\boldsymbol z=\boldsymbol x-\boldsymbol{\mu}_x$

那么$\mathbb{E}(\boldsymbol z)=0,\Sigma_{z}=\mathbb{E}(\boldsymbol{zz}^\top)=\Sigma_x$,$y_i=\boldsymbol{u}_i^\top\boldsymbol{z}$

由定义知，第一主成分的$\boldsymbol u_1$是在$\boldsymbol u_1^\top\boldsymbol u_1=1$的条件下，$\boldsymbol z$的所有线性变换使方差

$$
\text{var}(\boldsymbol u_1^\top\boldsymbol z)=\boldsymbol u_1^\top\Sigma_z\boldsymbol u_1
$$

达到最大，转换成约束最优化问题：

$$
\max_{\boldsymbol u_1}\boldsymbol u_1^\top\Sigma_z\boldsymbol u_1\\\text{s.t. }\boldsymbol{u}_1^\top\boldsymbol{u}_1=1
$$

定义拉格朗日函数

$$
L(\boldsymbol{u}_1, \lambda)=\boldsymbol u_1^\top\Sigma_z\boldsymbol u_1-\lambda(\boldsymbol{u}_1^\top\boldsymbol{u}_1-1)
$$

求导：
$$
\begin{aligned}
\dfrac{\partial L}{\partial\boldsymbol{u}_1}
&=\Sigma_z\boldsymbol{u}_1-\lambda\boldsymbol{u}_1\\
\end{aligned}

$$
令其为0：
$$

\Sigma_z\boldsymbol{u}_1=\lambda\boldsymbol{u}_1

$$
显然$\lambda,\boldsymbol{u}_1$分别是$\Sigma_{\boldsymbol z}$，也就是$\Sigma_{\boldsymbol x}$的特征值和对应的单位特征向量，代入，我们有
$$

\boldsymbol u_1^\top\Sigma_z\boldsymbol u_1=\lambda\boldsymbol{u}_1^\top\boldsymbol{u}_1=\lambda
$$
要使$\lambda$最大化，那必然是$\Sigma_x$特征值中的最大值，因此$\boldsymbol u_1$是$\Sigma_x$最大特征值对应的特征向量.



类似的，我们有

$$
\text{var}(\boldsymbol u_2^\top\boldsymbol z)=\boldsymbol u_2^\top\Sigma_z\boldsymbol u_2
$$

从而将问题转化为优化问题

$$
\max_{\boldsymbol u_2}\boldsymbol u_2^\top\Sigma_z\boldsymbol u_2
$$

s.t.

$$
\boldsymbol u_2^\top\boldsymbol u_1=0,\boldsymbol u_2^\top\boldsymbol u_2=1
$$

从而定义拉格朗日函数

$$
L(\boldsymbol u_2,\lambda,\phi)=\boldsymbol u_2^\top\Sigma_z\boldsymbol u_2-\lambda(\boldsymbol u_2^\top\boldsymbol u_2-1)-\phi\boldsymbol u_2^\top\boldsymbol u_1=0
$$

对$\boldsymbol{u}_2$求导并令其为0：
$$
\begin{aligned}
\dfrac{\partial L}{\partial\boldsymbol{u_2}}&=0\\
2\Sigma_z\boldsymbol{u}_2&=2\lambda\boldsymbol{u}_2+\phi\boldsymbol{u}_1\\
2\boldsymbol{u}_1^\top\Sigma_z\boldsymbol{u}_2 &= 2\lambda\boldsymbol{u}_1^\top\boldsymbol{u}_2+\phi\boldsymbol{u}_1^\top\boldsymbol{u}_1\\
0&=0+\phi\boldsymbol{u}_1^\top\boldsymbol{u}_1\\
\phi&=0
\end{aligned}

$$
代入，有
$$

2\Sigma_z\boldsymbol{u}_2=2\lambda\boldsymbol{u}_2

$$
显然$\lambda$是$\Sigma_z$的特征值，$\boldsymbol{u}_2$是对应的单位特征向量。于是目标函数：
$$

\boldsymbol u_2^\top\Sigma_z\boldsymbol u_2=\lambda\boldsymbol{u}_2^\top\boldsymbol{u}_2=\lambda
$$
当$\lambda$是$\Sigma_z$的第二大特征值$\lambda_2$，那么$\boldsymbol{u}_2$与$\lambda_2$是上面最优化问题的解。

$\textbf{function}\text{ EMClustering}(D,k):$
$\quad\textbf{input: }D=\{x_1,x_2,\cdots,x_N\},k$
$\quad\text{Initialze parameter }\sigma,\{(\pi_i,\mu_i)\vert1\leqslant i\leqslant k\}.$
$\quad\textbf{repeat}$
$\qquad\textbf{for }i=1,2,\cdots,N\textbf{ do}$
$\qquad\quad\text{Calculate }\gamma_{ij}\text{ we mentioned before}.$
$\qquad\textbf{end for}$
		$\textbf{for }j=1,2,\cdots,K\textbf{ do}:$
			$\mu_j'=\dfrac{\sum_{i=1}^N\gamma_{ij}x_i}{\sum_{i=1}^N\gamma_{ij}}$
			$\sigma'=\sqrt{\dfrac{1}{p}\sum_{i=1}^N\sum_{j=1}^K\gamma_{ij}(x_i-\mu_j)^\top(x_i-\mu_j)}$
			$\pi_j'=\dfrac{1}{N}\sum_{i=1}^N\gamma_{ij}$
		$\textbf{end for}$
		$\text{Update }\sigma,\{(\pi_i,\mu_i)\vert1\leqslant i\leqslant k\}\text{ with }\sigma',\{(\pi_i',\mu_i')\vert1\leqslant i\leqslant k\}$
	$\textbf{until}\text{ terminal condition is satisfied.}$
	$C_i=\emptyset(1\leqslant i\leqslant k)$
	$\textbf{for }i=1,2,\cdots,N\textbf{ do}$
		$\lambda_i=\mathop{\arg\max}\limits_{j\in\{1,2,\cdots K\}}\gamma_{ij}$
		$C_{\lambda_i}=C_{\lambda_i}\cup\{x_i\}$
	$\textbf{end for}$
$\textbf{returns }C=\{C_1,C_2,\cdots,C_K\}$

```Sarsa
      → → → → → → → → ↓
→ → → ↑               ↓
↑                     ↓
↑ C C C C C C C C C C ↓
```

```qlearn


→ → → → → → → → → → → ↓
↑ C C C C C C C C C C ↓
```

```sarsa_3
        → → → → ↓
→ → → → ↑       → → → ↓
↑                     ↓
↑ C C C C C C C C C C ↓
```

```sarsa-1
  → → ↓   → → → → → → ↓
  ↑   → → ↑           ↓
→ ↑                   ↓
↑ C C C C C C C C C C ↓
```

```sarsa-5
          → → → → → → ↓
→ → ↓ → → ↑           ↓
↑   → ↑               ↓
↑ C C C C C C C C C C ↓
```

```sarsa-5-1000
→ → → → → → → → ↓
↑               → → → ↓
↑                     ↓
↑ C C C C C C C C C C ↓
```

```lambda-0.5-1000
→ → → → → → → → → → → ↓
↑                     ↓
↑                     ↓
↑ C C C C C C C C C C ↓
```

$$
\begin{aligned}
\|T\|&=\sup\dfrac{\|Tx\|}{\|x\|}\\
&=\sup\dfrac{\int_a^bx(t)\mathrm dt}{\max |x(t)|}\\
&=\dfrac{\int_a^b\max |f(x)|\mathrm dx}{\max |f(x)|}\\
&=b-a
\end{aligned}


$$

$$


\int_a^b f(x)\mathrm dx\leqslant(b-a)\max|f(x)|
$$

1，7，14，15不考

选择题5题，10道填空题，5道实验题（最经典最有代表性的实验），2道论述题；

2. 认知神经科学：what，修建机制，大脑区域，及其对应能力；技术及其原理，
3. 视觉与模式识别：错觉原理，先备知识，运动控制/特征属性，“9字母实验”；模式识别：视觉细胞及其作用，大概了解模式识别各项理论，自下而上和自上而下，
4. 注意力：双耳分听任务，鸡尾酒会，各种模型；弹出效应，视野忽视的原因；能不能一心二用：实验和区别，斯特鲁普的原理。
5. 记忆过程：Brown-Peterson技术；Baddelay的工作记忆模型、
6. 记忆模型：Clark 1975实验，记忆类型，三个圈，普鲁斯特现象，闪光灯记忆；
7. 知识表征：二阶同构，两种知识
8. 人类语言的特征，表层结构，语言相对性假设，蚂蚁吃果冻
9. 金茨理解模型，
10. 思维，创造四阶段






$$
\begin{aligned}
p(Z=z)&=\int_{}p_x(X=x)p_y(Y=z-2x)\mathrm dx\\
&=\int_0^1 f(x)g(z-2x)\mathrm dx\\
&=\int_0^1 g(z-2x)\mathrm dx,其中z-2x\in[z-2,z]
\end{aligned}
$$


EL一开始的判定问题算法：

- simpleR规则：$A'\in S(A)$ and $A'\sqsubseteq B$ and $B\notin S(A)$, then $S(A)\gets S(A)\cup\{B\}$
- conjR规则：$A_1\sqcap A_2\sqsubseteq B$ and $A_1,A_2\in S(A)$, then $S(A)\gets S(A)\cup\{B\}$
- rightR规则：$A'\sqsubseteq\exists r.B$ and $A'\in S(A)$ and $(A, B)\notin R(r)$, then $R(r)\gets R(r)\cup\{(A,B)\}$
- leftR规则：$\exists r.B'\sqsubseteq A'$ and $B'\in S(B)$ and $(A,B)\in R(r)$, then $S(A)\gets S(A)\cup\{A'\}$

EL构建模型算法：

- simpleR规则：$A\sqsubseteq B$ and $A\in S(d)$, then $S(d)\gets S(d)\cup\{B\}$
- conjR规则：$A_1\sqcap A_2\sqsubseteq B$ and $A_1,A_2\in S(d)$, then $S(d)\gets S(d)\cup\{B\}$
- rightR规则：$A\sqsubseteq\exists r.B$ and $A\in S(d)$ and $(d,d_B)\notin R(r)$, then $R(r)\gets R(r)\cup\{(d,d_B)\}$
- leftR规则：$\exists r.B\sqsubseteq A$ and $(d_1,d_2)\in R(r)$ and $B\in S(d_2)$, then $S(d_1)\gets S(d_1)\cup\{A\}$

$$
\begin{aligned}
S(d_\text{BasketClub})&=\{\text{BasketClub},\text{Club}\}\\
S(d_\text{Basketplayer})&=\{\text{Basketplayer},\text{Player},\text{Human}\}\\
S(d_\text{Club})&=\{\text{Club}\}\\
S(d_\text{Player})&=\{\text{Player},\text{Player}\}\\
S(d_\text{Human})&=\{\text{Human}\}\\
R(\text{plays_for})&=\{(\text{rob},\text{tigers}),(\text{bob},\text{lion}),(d_\text{BasketPlayer},d_\text{BasketClub}),(\text{bob},d_\text{BasketClub}) \}\\
S(\text{bob})&=\{\text{BasketPlayer},\text{Player},\text{Human}\}\\
S(\text{jim})&=\{\text{Player},\text{Human}\}\\
S(\text{tigers})&=\{\text{Basketclub},\text{Club}\}\\
S(\text{lions})&=\{\text{Club}\}\\
S(\text{rob})&=\{\text{Player}\}
\end{aligned}
$$

**A4纸**

不考定义

选择

填空 10

实验 5

论述 2



第二章

大脑分区 位置 几个技术与原理 TMS 实验范式测什么 大脑半球的实验（左半球什么什么中枢）面孔实验

第三章

感觉对应的感知器 感觉和知觉的区别 错觉原理 先备知识 WM两个信息加工 部分报告法，重要意义

模式识别 视锥细胞视感细胞功能 视觉模式识别理论的大概了解 消防栓（自上而下自下而上）

特征分析的两个证据 面孔识别加工3个实验 棱状面空区

第四章

注意 分成几个注意 衰减器模型 视野忽视 中枢瓶颈

第五章

记忆 工作记忆的模块 

第六章

记忆模型 记忆区域 三个圈之间的逻辑关系 闪光灯记忆概念

第八章

知识表征 知道语义情节大的分类就已经足够了 论述题！！！！

第九章

双重编码 实验题

第十章

理解内容 语言学基本知识不考 乔姆斯基语法理论基本的知识点

第十一章

蚂蚁吃果冻实验 情景模型

第十二章

思维定义不会考 假设检验 四种特点的名字和大概意思 许可图式 心理表征的形象性

太细了没法考

第十三章





